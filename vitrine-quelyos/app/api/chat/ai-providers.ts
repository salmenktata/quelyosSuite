/**
 * Providers IA pour l'Assistant Quelyos
 *
 * Ce fichier contient les int√©grations avec diff√©rentes IA :
 * - Groq (Gratuit - Llama 3.1)
 * - Anthropic Claude
 * - OpenAI GPT-4
 *
 * Configuration dynamique depuis le backend Odoo.
 */

import { createApiLogger } from '@/lib/logger';
import { getAiConfig, reportAiUsage, type AiProviderConfig } from '@/lib/ai-config';

const log = createApiLogger('POST /api/chat/ai-providers');

interface AIMessage {
  role: 'user' | 'assistant';
  content: string;
}

interface AIResponse {
  response: string;
  suggestions: string[];
  confidence: number;
  provider: 'groq' | 'claude' | 'openai' | 'local';
}

const SYSTEM_PROMPT = `Tu es l'assistant virtuel de Quelyos Suite, une plateforme ERP fran√ßaise pour TPE/PME.

üè¢ CONTEXTE ENTREPRISE :
- 8 modules int√©gr√©s : Finance (IA pr√©visions 90j), Boutique, CRM, Stock, RH, POS, Marketing, Dashboard
- Toutes les donn√©es synchronis√©es automatiquement entre modules
- IA de pr√©vision tr√©sorerie : pr√©cision 85-90% sur 90 jours
- H√©bergement 100% France, certifi√© ISO 27001
- 100% conforme RGPD, donn√©es chiffr√©es AES-256
- 2500+ entreprises clientes (TPE/PME fran√ßaises)

üí∞ TARIFS :
- Starter : 19‚Ç¨/mois (3 users, Finance + 2 modules au choix, IA 12 mois)
- Business : 49‚Ç¨/mois (10 users, tous les 8 modules, IA 24 mois, API compl√®te) ‚≠ê Meilleur rapport
- Enterprise : Sur devis (users illimit√©s, SLA 99.9%, account manager d√©di√©)
- üéÅ 30 jours d'essai gratuit SANS carte bancaire sur tous les plans

‚ú® POINTS FORTS :
- Tout-en-un vs 5-6 logiciels s√©par√©s chez la concurrence
- Prix fixe transparent vs modules additionnels cach√©s
- Support fran√ßais r√©actif (24h standard, 4h premium)
- Installation en 5 minutes, donn√©es migr√©es en 2-5 jours

üéØ TON R√îLE :
- R√©pondre de mani√®re CLAIRE, CONCISE et ACTIONABLE
- √ätre enthousiaste mais professionnel (jamais vendeur agressif)
- Utiliser des emojis avec parcimonie (1-2 max par r√©ponse)
- Structurer tes r√©ponses : titre ‚Üí bullet points ‚Üí call-to-action
- TOUJOURS proposer 2-3 actions concr√®tes en fin de r√©ponse
- Si tu ne sais pas ou question trop sp√©cifique ‚Üí rediriger vers support@quelyos.com

üìù STYLE D'√âCRITURE :
- Tutoiement naturel et friendly
- Phrases courtes (15-20 mots max)
- Paragraphes a√©r√©s (2-3 lignes max)
- Bullet points pour les listes
- √âviter le jargon technique (sauf si l'user demande)
- Reformuler les acronymes la 1√®re fois (ex: "CRM (gestion clients)")

üö´ INTERDICTIONS :
- JAMAIS inventer des features qui n'existent pas
- JAMAIS donner de faux chiffres ou stats
- JAMAIS promettre des d√©lais sans √™tre s√ªr
- JAMAIS d√©nigrer la concurrence (parler de nos avantages positivement)

üí° EXEMPLES DE BONNES R√âPONSES :

User: "C'est quoi la diff√©rence avec Excel ?"
Assistant: "Excel est excellent pour les calculs ponctuels, mais Quelyos va beaucoup plus loin :

üìä **Excel** : Saisie manuelle, risques d'erreur, pas de collaboration
üíé **Quelyos** : Import auto banques, IA pr√©visions 90j, sync temps r√©el √©quipe

Les avantages concrets :
‚Ä¢ Gain de temps : 10h/mois √©conomis√©es en moyenne
‚Ä¢ Pr√©visions fiables : l'IA apprend de tes donn√©es
‚Ä¢ Travail d'√©quipe : modifications visibles instantan√©ment

‚Üí [Voir une d√©mo] [Comparer en d√©tail] [Essai gratuit]"

User: "Vous faites la compta ?"
Assistant: "Quelyos n'est pas un logiciel comptable pur, mais ton meilleur alli√© pour la gestion financi√®re :

‚úÖ **Ce qu'on fait** :
‚Ä¢ Tr√©sorerie et pr√©visions
‚Ä¢ Cat√©gorisation intelligente des d√©penses
‚Ä¢ Budgets et alertes
‚Ä¢ Export FEC pour ton expert-comptable

ü§ù **Int√©gration comptable** :
On se connecte avec ton logiciel compta (Sage, Cegid, etc.) pour synchroniser automatiquement.

Pense √† Quelyos comme le pilotage au quotidien, ton comptable fait la d√©claration fiscale.

‚Üí [Voir module Finance] [Int√©grations comptables] [Parler √† un expert]"

üéØ FORMAT DE R√âPONSE ATTENDU :
1. Phrase d'accroche (reformuler la question)
2. R√©ponse structur√©e (bullet points)
3. Exemple concret si pertinent
4. 2-3 suggestions d'actions entre crochets

Pr√™t √† assister les utilisateurs de mani√®re professionnelle et efficace !`;

/**
 * Groq (Gratuit) - Llama 3.1 70B Versatile
 * Ultra-rapide (~300 tokens/s), gratuit (14400 req/jour)
 */
async function getGroqResponse(
  message: string,
  history: AIMessage[],
  config: AiProviderConfig
): Promise<AIResponse> {
  if (!config.api_key) {
    throw new Error('Groq API key not configured');
  }

  try {
    const Groq = (await import('groq-sdk')).default;

    const groq = new Groq({
      apiKey: config.api_key,
    });

    const completion = await groq.chat.completions.create({
      model: config.model || 'llama-3.1-70b-versatile',
      messages: [
        { role: 'system', content: SYSTEM_PROMPT },
        ...history.map(h => ({ role: h.role, content: h.content })),
        { role: 'user', content: message }
      ],
      temperature: config.temperature || 0.7,
      max_tokens: config.max_tokens || 800,
      top_p: 1,
    });

    const responseText = completion.choices[0].message.content || '';
    const suggestions = extractSuggestionsFromText(responseText);

    return {
      response: responseText,
      suggestions,
      confidence: 0.90,
      provider: 'groq'
    };

  } catch (error) {
    log.error('[Groq] Erreur API:', error);
    throw error;
  }
}

/**
 * Anthropic Claude
 * Meilleur rapport qualit√©/prix et compr√©hension contextuelle
 */
async function getClaudeResponse(
  message: string,
  history: AIMessage[],
  config: AiProviderConfig
): Promise<AIResponse> {
  if (!config.api_key) {
    throw new Error('Claude API key not configured');
  }

  try {
    const Anthropic = (await import('@anthropic-ai/sdk')).default;

    const anthropic = new Anthropic({
      apiKey: config.api_key,
    });

    const response = await anthropic.messages.create({
      model: config.model || 'claude-3-5-sonnet-20241022',
      max_tokens: config.max_tokens || 800,
      temperature: config.temperature || 0.7,
      system: SYSTEM_PROMPT,
      messages: [
        ...history,
        { role: 'user', content: message }
      ]
    });

    const responseText = response.content[0].type === 'text'
      ? response.content[0].text
      : '';

    const suggestions = extractSuggestionsFromText(responseText);

    return {
      response: responseText,
      suggestions,
      confidence: 0.92,
      provider: 'claude'
    };

  } catch (error) {
    log.error('Erreur Claude API:', error);
    throw error;
  }
}

/**
 * OpenAI GPT-4
 * Alternative si Claude indisponible
 */
export async function getOpenAIResponse(
  message: string,
  history: AIMessage[]
): Promise<AIResponse> {
  if (!process.env.OPENAI_API_KEY) {
    throw new Error('OPENAI_API_KEY manquante');
  }

  try {
    const OpenAI = (await import('openai')).default;

    const openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });

    const completion = await openai.chat.completions.create({
      model: 'gpt-4-turbo-preview',
      messages: [
        { role: 'system', content: SYSTEM_PROMPT },
        ...history,
        { role: 'user', content: message }
      ],
      temperature: 0.7,
      max_tokens: 700,
      presence_penalty: 0.6,
      frequency_penalty: 0.3
    });

    const responseText = completion.choices[0].message.content || '';
    const suggestions = extractSuggestionsFromText(responseText);

    return {
      response: responseText,
      suggestions,
      confidence: 0.90,
      provider: 'openai'
    };

  } catch (error) {
    log.error('Erreur OpenAI API:', error);
    throw error;
  }
}

/**
 * Extraire les suggestions du texte
 * Cherche les actions entre crochets : [Action]
 */
function extractSuggestionsFromText(text: string): string[] {
  // Chercher les suggestions entre crochets
  const bracketMatches = text.match(/\[([^\]]+)\]/g);
  if (bracketMatches && bracketMatches.length > 0) {
    return bracketMatches
      .map(match => match.replace(/[\[\]]/g, ''))
      .slice(0, 4); // Max 4 suggestions
  }

  // Fallback : suggestions par d√©faut contextuelles
  const suggestions: string[] = [];

  if (text.toLowerCase().includes('tarif') || text.toLowerCase().includes('prix')) {
    suggestions.push('Voir les tarifs d√©taill√©s', 'Comparer les plans');
  }

  if (text.toLowerCase().includes('module') || text.toLowerCase().includes('fonctionnalit√©')) {
    suggestions.push('D√©couvrir les 8 modules', 'Voir des d√©mos');
  }

  if (text.toLowerCase().includes('essai') || text.toLowerCase().includes('gratuit')) {
    suggestions.push('D√©marrer l\'essai gratuit');
  }

  // Toujours proposer ces actions
  if (suggestions.length < 3) {
    suggestions.push('Cr√©er mon compte', 'Contacter le support');
  }

  return suggestions.slice(0, 3);
}

/**
 * Router intelligent avec configuration dynamique depuis le backend.
 * Utilise le provider configur√© dans le panel Super Admin.
 */
export async function getAIResponse(
  message: string,
  history: AIMessage[]
): Promise<AIResponse> {
  const startTime = Date.now();

  try {
    // R√©cup√©rer la config dynamique depuis le backend
    const config = await getAiConfig();

    if (!config) {
      throw new Error('No active AI provider configured in backend');
    }

    log.info(`[AI] Using provider: ${config.provider} (${config.model})`);

    let response: AIResponse;

    // Router selon le provider configur√©
    if (config.provider === 'groq') {
      response = await getGroqResponse(message, history, config);
    } else if (config.provider === 'claude') {
      response = await getClaudeResponse(message, history, config);
    } else if (config.provider === 'openai') {
      response = await getOpenAIResponse(message, history);
    } else {
      throw new Error(`Unsupported provider: ${config.provider}`);
    }

    const latency = Date.now() - startTime;
    log.info(`[AI] ‚úÖ Success with ${config.provider} (${latency}ms)`);

    // Reporter les m√©triques au backend (async, non-bloquant)
    reportAiUsage(
      config.id,
      0, // tokens_used (TODO: extraire des r√©ponses API)
      0, // cost
      latency,
      true
    ).catch(err => log.warn('[AI] Failed to report usage:', err));

    return response;

  } catch (error) {
    const latency = Date.now() - startTime;
    log.error('[AI] Provider failed:', error);

    // Reporter l'√©chec si on a la config
    const config = await getAiConfig().catch(() => null);
    if (config) {
      reportAiUsage(config.id, 0, 0, latency, false)
        .catch(() => {/* ignore */});
    }

    throw error;
  }
}

/**
 * Formater l'historique pour les APIs IA
 */
export function formatHistoryForAI(
  history: Array<{ type: 'user' | 'bot'; text: string }>
): AIMessage[] {
  return history
    .slice(-8) // Garder seulement les 8 derniers messages
    .map(msg => ({
      role: msg.type === 'user' ? 'user' : 'assistant',
      content: msg.text
    }));
}
